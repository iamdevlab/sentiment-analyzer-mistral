# ğŸ§  Sentiment Analyzer (Mistral)

A simple AI-powered web application that classifies the sentiment of text as **Positive**, **Negative**, or **Neutral** using the **Mistral** model (via [Ollama](https://ollama.com)), with a **FastAPI** backend and **Streamlit** frontend.

---

## âœ¨ Features
- âš¡ **FastAPI Backend** â€“ Handles text input and communicates with the Mistral model for sentiment classification.
- ğŸ¨ **Streamlit Frontend** â€“ Clean, interactive interface for entering text and viewing predictions.
- ğŸ’» **Runs Locally** â€“ Uses Ollama to host the Mistral model directly on your machine.
- ğŸ”— **Git & GitHub** â€“ Version control and easy deployment.

---

## ğŸ“‚ Project Structure
```
sentiment-analyzer-mistral/
â”‚
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ main.py           # FastAPI backend
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py            # Streamlit frontend
â”‚
â”œâ”€â”€ venv/                 # Virtual environment (excluded in .gitignore)
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Documentation
```

---

## ğŸš€ Installation & Setup

### **1. Install Python**
- Download & install Python from [python.org/downloads](https://www.python.org/downloads/).
- Ensure you check **"Add Python to PATH"** during installation.

### **2. Clone the Repository**
```bash
git clone https://github.com/iamdevlab/sentiment-analyzer-mistral.git
cd sentiment-analyzer-mistral
```

### **3. Create & Activate Virtual Environment**
**Windows (PowerShell)**:
```powershell
python -m venv venv
venv\Scripts\Activate.ps1
```
**Mac/Linux**:
```bash
python3 -m venv venv
source venv/bin/activate
```

### **4. Install Dependencies**
```bash
pip install -r requirements.txt
```

### **5. Install Ollama & Mistral Model**
- Download Ollama from [ollama.com/download](https://ollama.com/download).  
- Pull the Mistral model:
```bash
ollama pull mistral
```

---

## â–¶ï¸ Running the App

### **Run Backend (FastAPI)**
```bash
uvicorn backend.main:app --reload
```
Backend runs at: **http://localhost:8000**

### **Run Frontend (Streamlit)**
In a new terminal:
```bash
streamlit run frontend/app.py
```
Frontend runs at: **http://localhost:8501**

---

## ğŸ“Š Workflow Diagram
![Workflow Diagram](docs/workflow.png)  
*(User â†’ Streamlit â†’ FastAPI â†’ Ollama (Mistral) â†’ Sentiment Output)*

---

## ğŸ›  Tech Stack
- **[Python](https://www.python.org/)** â€“ Programming language
- **[FastAPI](https://fastapi.tiangolo.com/)** â€“ Backend API
- **[Streamlit](https://streamlit.io/)** â€“ Frontend UI
- **[Ollama](https://ollama.com/)** â€“ Local Mistral model hosting
- **[Git & GitHub](https://github.com/)** â€“ Version control

---

## ğŸ“œ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ’¡ Author
Developed by **[Vernon Usigbe](https://github.com/iamdevlab)**.  
If you find this useful, â­ the repo and share it!
